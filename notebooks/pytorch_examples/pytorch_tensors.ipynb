{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pytorch basics\n",
    "\n",
    "torch equivalents of numpy functions\n",
    "\n",
    "### Types\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| np.ndarray       | torch.Tensor\n",
    "| np.float32       | torch.FloatTensor\n",
    "| np.float64       | torch.DoubleTensor\n",
    "| np.int8          | torch.CharTensor\n",
    "| np.uint8         | torch.ByteTensor\n",
    "| np.int16         | torch.ShortTensor\n",
    "| np.int32         | torch.IntTensor\n",
    "| np.int64         | torch.LongTensor\n",
    "\n",
    "### Constructors\n",
    "#### Ones and zeros\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| np.empty([2,2]) | torch.Tensor(2,2)\n",
    "| np.empty_like(x) | x.new(x:size())\n",
    "| np.eye           | torch.eye\n",
    "| np.identity      | torch.eye\n",
    "| np.ones          | torch.ones\n",
    "| np.ones_like     | torch.ones(x:size())\n",
    "| np.zeros         | torch.zeros\n",
    "| np.zeros_like    | torch.zeros(x:size())\n",
    "\n",
    "#### From existing data\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| np.array([ [1,2],[3,4] ])   | torch.Tensor({{1,2},{3,4}})\n",
    "| np.ascontiguousarray(x)   | x:contiguous()\n",
    "| np.copy(x)    | x:clone()\n",
    "| np.fromfile(file) | torch.Tensor(torch.Storage(file))\n",
    "| np.concatenate | torch.cat\n",
    "| np.multiply | torch.cmul\n",
    "\n",
    "#### Numerical Ranges\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| np.arange(10)    | torch.range(0,9)\n",
    "| np.arange(2, 3, 0.1) | torch.linspace(2, 2.9, 10)\n",
    "| np.linspace(1, 4, 6) | torch.linspace(1, 4, 6)\n",
    "| np.logspace | torch.logspace\n",
    "\n",
    "#### Building Matrices\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| np.diag | torch.diag\n",
    "| np.tril | torch.tril\n",
    "| np.triu | torch.triu\n",
    "\n",
    "#### Attributes\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| x.shape | x:size()\n",
    "| x.strides | x:stride()\n",
    "| x.ndim | x:dim()\n",
    "| x.data | x:data()\n",
    "| x.size | x:nElement()\n",
    "| x.size == y.size | x:isSameSizeAs(y)\n",
    "| x.dtype | x:type()\n",
    "\n",
    "#### Indexing\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "\n",
    "#### Shape Manipulation\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| x.reshape | x:reshape\n",
    "| x.resize | x:resize\n",
    "| ?        | x:resizeAs\n",
    "| x.transpose | x:transpose()\n",
    "| x.flatten   | x:view(x:nElement())\n",
    "| x.squeeze   | x:squeeze\n",
    "\n",
    "#### Item selection and manipulation\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| np.take(a, indices) | a[indices]\n",
    "| x[:,0]  | x[{{},1}]\n",
    "| x.repeat | x:repeatTensor\n",
    "| x.fill | x:fill\n",
    "| np.sort | sorted, indices = torch.sort(x, [dim])\n",
    "| np.argsort | sorted, indices = torch.sort(x, [dim])\n",
    "| np.nonzero | torch.find(x:gt(0), 1) (torchx)\n",
    "\n",
    "#### Calculation\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| ndarray.min | mins, indices = torch.min(x, [dim])\n",
    "| ndarray.argmin | mins, indices = torch.min(x, [dim])\n",
    "| ndarray.max | maxs, indices = torch.max(x, [dim])\n",
    "| ndarray.argmax | maxs, indices = torch.max(x, [dim])\n",
    "| ndarray.trace | torch.trace\n",
    "| ndarray.sum | torch.sum\n",
    "| ndarray.cumsum | torch.cumsum\n",
    "| ndarray.mean | torch.mean\n",
    "| ndarray.std | torch.std\n",
    "| ndarray.prod | torch.prod\n",
    "| ndarray.dot | torch.mm\n",
    "| ndarray.cumprod | torch.cumprod\n",
    "\n",
    "#### Arithmetic and comparison operations\n",
    "| Numpy            | Torch |\n",
    "| --------------------|:-------------:|\n",
    "| ndarray.__lt__ | torch.lt\n",
    "| ndarray.__le__ | torch.le\n",
    "| ndarray.__gt__ | torch.gt\n",
    "| ndarray.__ge__ | torch.ge\n",
    "| ndarray.__eq__ | torch.eq\n",
    "| ndarray.__ne__ | torch.ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-27 *\n",
      "  2.4784  0.0000  2.4784\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2844  0.7242  0.0426\n",
      " 0.3275  0.5257  0.8098\n",
      " 0.0927  0.0479  0.1398\n",
      " 0.2899  0.0207  0.1228\n",
      " 0.2055  0.5918  0.4943\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.9250  0.7656  1.7955\n",
      " 0.6470  1.1248  1.0972\n",
      " 1.6441  1.0679  1.7334\n",
      " 0.8841  1.0173  0.9987\n",
      " 1.1600  1.0336  1.3144\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3  3  3\n",
      " 3  3  3\n",
      " 3  3  3\n",
      " 3  3  3\n",
      " 3  3  3\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, 3)*2\n",
    "y = torch.ones(5,1)\n",
    "\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inplace operations\n",
    "\n",
    "- `torch.add(x, y, out=result)`\n",
    "\n",
    "\n",
    "Any operation that mutates a tensor in-place is post-fixed with an _ \n",
    "\n",
    "For example: `x.copy_(y), x.t_(),...` will change x.\n",
    "\n",
    "A description of the operations avaliable in torch can be found here:\n",
    "\n",
    "http://pytorch.org/docs/master/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 4  4  4\n",
      " 4  4  4\n",
      " 4  4  4\n",
      " 4  4  4\n",
      " 4  4  4\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 5x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = torch.ones(5,1)\n",
    "y.add_(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatibility between Numpy arrays and torch tensors\n",
    "\n",
    "You can cast a numpy `X` to a torch tensor by simply writting: `torch.Tensor(X)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor(np.random.rand(10))\n",
    "print(t.size())\n",
    "\n",
    "t = torch.Tensor(np.random.rand(10, 1))\n",
    "print(t.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can cast from torch tensor to `np.ndarray` using `.numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch array of size:  torch.Size([5]) \n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "numpy array of size:  (5,) [ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(\"torch array of size: \", a.size() , a)\n",
    "b = a.numpy()\n",
    "print(\"numpy array of size: \", b.shape, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operations of torch arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "[ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.]\n",
      "\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting numpy Array to torch Tensor\n",
    "import numpy as np\n",
    "a = np.zeros(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.bmm function\n",
    "\n",
    "bmm(batch1, batch2, out=None) -> Tensor\n",
    "\n",
    "\n",
    "$$\n",
    "C_{[a,b,d]} = bmm(A_{[a, b, c]}, B_{[a, c, d]} )\n",
    "$$\n",
    "\n",
    "\n",
    "Performs a batch matrix-matrix product of matrices stored in `batch1`\n",
    "and `batch2`.\n",
    "\n",
    "`batch1` and `batch2` must be 3D Tensors each containing\n",
    "the same number of matrices.\n",
    "\n",
    "If `batch1` is a `b x n x m` Tensor, `batch2` is a `b x m x p`\n",
    "Tensor, `out` will be a `b x n x p` Tensor.\n",
    "\n",
    "\n",
    "\n",
    "Args:\n",
    "    batch1 (Tensor): First batch of matrices to be multiplied\n",
    "    batch2 (Tensor): Second batch of matrices to be multiplied\n",
    "    out (Tensor, optional): Output tensor\n",
    "\n",
    "Example::\n",
    "\n",
    "    >>> batch1 = torch.randn(10, 3, 4)\n",
    "    >>> batch2 = torch.randn(10, 4, 5)\n",
    "    >>> res = torch.bmm(batch1, batch2)\n",
    "    >>> res.size()\n",
    "    torch.Size([10, 3, 5])\n",
    "    \n",
    "    \n",
    "#### torch.bmm([res,] batch1, batch2)\n",
    "\n",
    "Batch matrix matrix product of matrices stored in batch1 and batch2. batch1 and batch2 must be 3D tensors each containing the same number of matrices. If batch1 is a `b x n x m` tensor, batch2 a `b x m x p` tensor, res will be a `b x n x p` tensor.\n",
    "\n",
    "- `torch.bmm(x,y)` puts the result in a new tensor.\n",
    "\n",
    "- `torch.bmm(M,x,y)` puts the result in M, resizing M if necessary.\n",
    "\n",
    "- `M.bmm(x,y)` puts the result in M, resizing M if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch1 = torch.randn([10, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch2 = torch.randn([10, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.bmm(batch1, batch2)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4494  0.1679  0.1083  1.2730  0.0031\n",
       " 1.2214  2.4258 -2.3082 -3.5297 -1.3011\n",
       " 0.3496  0.9036 -2.8845  3.5618 -2.6899\n",
       "[torch.FloatTensor of size 3x5]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1  1  1\n",
       " 1  1  1  1  1\n",
       " 1  1  1  1  1\n",
       "[torch.ByteTensor of size 3x5]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1] == batch1[1] @ batch2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1  1  1\n",
       " 1  1  1  1  1\n",
       " 1  1  1  1  1\n",
       "[torch.ByteTensor of size 3x5]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2] == batch1[2] @ batch2[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore `torch.bmm` essentially does a matrix multiplication for each of the 10 matrices in batch1 and batch2.\n",
    "\n",
    "Notice that \n",
    "\n",
    "```python\n",
    "batch1 = torch.randn([10, 3, 4])\n",
    "batch2 = torch.randn([9, 4, 5])\n",
    "res = torch.bmm(batch1, batch2)\n",
    "```\n",
    "\n",
    "Would not work since `batch1` contains 10 matrices and `batch2` contains 9 matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: equal number of batches expected, got 10, 9 at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:1509",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-858d4c71f552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: equal number of batches expected, got 10, 9 at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:1509"
     ]
    }
   ],
   "source": [
    "batch1 = torch.randn([10, 3, 4])\n",
    "batch2 = torch.randn([9, 4, 5])\n",
    "res = torch.bmm(batch1, batch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogously `torch.bmm` needs the matrices from `batch1` and `batch2` to be compatible.\n",
    "\n",
    "Therefore, in the following example, even though the number of matrices from `batch1` and `batch2` is the same (there are 10 matrices).\n",
    "The matrix shapes are not compatible $M_{(3,4)} \\cdot  M_{(3,5)}$ is not a valid matric multiplications (shapes don't match).\n",
    "\n",
    "```python\n",
    "batch1 = torch.randn([10, 3, 4])\n",
    "batch2 = torch.randn([10, 3, 5])\n",
    "res = torch.bmm(batch1, batch2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: wrong matrix size, batch1: 3x4, batch2: 3x5 at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:1513",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-6cf47cc762a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: wrong matrix size, batch1: 3x4, batch2: 3x5 at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:1513"
     ]
    }
   ],
   "source": [
    "batch1 = torch.randn([10, 3, 4])\n",
    "batch2 = torch.randn([10, 3, 5])\n",
    "res = torch.bmm(batch1, batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
