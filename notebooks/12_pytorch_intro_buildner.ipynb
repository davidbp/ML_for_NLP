{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Perceptron demo for deliverable 2\n",
    "\n",
    "## Overview of the data\n",
    "\n",
    "url = https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\n",
    "\n",
    "\n",
    "Essential info about entities:\n",
    "\n",
    "```\n",
    "geo = Geographical Entity\n",
    "org = Organization\n",
    "per = Person\n",
    "gpe = Geopolitical Entity\n",
    "tim = Time indicator\n",
    "art = Artifact\n",
    "eve = Event\n",
    "nat = Natural Phenomenon\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mner.csv\u001b[m\u001b[m         \u001b[1m\u001b[31mner_dataset.csv\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/kaggle_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"kaggle_ner\"\n",
    "parent_path = \"../data\"\n",
    "\n",
    "def stringbold(string):\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'\n",
    "    return BOLD + string + END\n",
    "\n",
    "def download_kaggle_ner(foldername, parent_path):\n",
    "\n",
    "    url = \"/https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus/downloads/entity-annotated-corpus.zip\"\n",
    "    full_path = os.path.join(parent_path, foldername)\n",
    "    \n",
    "    if foldername not in os.listdir(parent_path):\n",
    "        print(\"Folder {} not found in {}\".format(stringbold(foldername),stringbold(parent_path)))\n",
    "        print(\"Creating folder {}\".format(stringbold(full_path)))\n",
    "        print(\"\\nDownload the data from \\n{} \\n Write 'ner_dataset.csv' and 'ner.csv' in {}  \"\\\n",
    "              .format(stringbold(url),full_path))\n",
    "        os.mkdir(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = os.path.join(parent_path, foldername)\n",
    "url = \"/https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus/downloads/entity-annotated-corpus.zip\"\n",
    "download_kaggle_ner(foldername, parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence #,Word,POS,Tag\r",
      "\r\n",
      "Sentence: 1,Thousands,NNS,O\r",
      "\r\n",
      ",of,IN,O\r",
      "\r\n",
      ",demonstrators,NNS,O\r",
      "\r\n",
      ",have,VBP,O\r",
      "\r\n",
      ",marched,VBN,O\r",
      "\r\n",
      ",through,IN,O\r",
      "\r\n",
      ",London,NNP,B-geo\r",
      "\r\n",
      ",to,TO,O\r",
      "\r\n",
      ",protest,VB,O\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# This should print the head of the csv\n",
    "! head ../data/kaggle_ner/ner_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/kaggle_ner/ner_dataset.csv\",\n",
    "                   encoding=\"latin1\")\n",
    "\n",
    "sentence_formatter = \"Sentence: {}\"\n",
    "\n",
    "last_n = 2000\n",
    "end   = data.index[data[\"Sentence #\"] == sentence_formatter.format(last_n)][0]\n",
    "data = data[0:end]\n",
    "\n",
    "n_sentences = len(list(set(data[\"Sentence #\"])))\n",
    "first_n = 1\n",
    "last_n = last_n -1\n",
    "print(n_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.47 s, sys: 160 ms, total: 7.63 s\n",
      "Wall time: 7.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "sentence_formatter = \"Sentence: {}\"\n",
    "\n",
    "for s_id in  range(first_n, last_n):\n",
    "    print(\"current {}/{}\".format(s_id,last_n), end=\"\\r\")\n",
    "    sentence_id = sentence_formatter.format(s_id)\n",
    "    sentence_id_next = sentence_formatter.format(s_id + 1)\n",
    "    start = data.index[data[\"Sentence #\"] == sentence_id][0]\n",
    "    end   = data.index[data[\"Sentence #\"] == sentence_id_next][0]\n",
    "    data[\"Sentence #\"][start:end] = sentence_id\n",
    "    \n",
    "sentence_id = sentence_formatter.format(last_n)\n",
    "start = data.index[data[\"Sentence #\"] == sentence_id][0]\n",
    "end   = data.shape[0]\n",
    "data[\"Sentence #\"][start:end] = sentence_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the information of a single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspected       O\n",
      "Islamist        O\n",
      "rebels          O\n",
      "have            O\n",
      "fired           O\n",
      "mortar          O\n",
      "shells          O\n",
      "at              O\n",
      "the             O\n",
      "palace          O\n",
      "used            O\n",
      "by              O\n",
      "Somalia         B-geo\n",
      "'s              O\n",
      "interim         O\n",
      "President       B-per\n",
      "Abdullahi       I-per\n",
      "Yusuf           I-per\n",
      "Ahmad           I-per\n",
      ".               O\n"
     ]
    }
   ],
   "source": [
    "index_example = 19\n",
    "n_w = 15\n",
    "sentence_id = \"Sentence: {}\".format(index_example)\n",
    "\n",
    "df_sentence = data[data[\"Sentence #\"]==sentence_id]\n",
    "x = list(df_sentence[\"Word\"])\n",
    "y = list(df_sentence[\"Tag\"])\n",
    "\n",
    "for w,t in zip(x,y):\n",
    "    w = w.ljust(n_w)\n",
    "    print(\"{0} {1}\".format(w,t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "sentence_formatter = \"Sentence: {}\"\n",
    "\n",
    "for i in range(1,n_sentences):\n",
    "    s = sentence_formatter.format(i)\n",
    "    X.append(list(data[data[\"Sentence #\"]==s][\"Word\"].values))\n",
    "    Y.append(list(data[data[\"Sentence #\"]==s][\"Tag\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands/O of/O demonstrators/O have/O marched/O through/O London/B-geo to/O protest/O the/O war/O in/O Iraq/B-geo and/O demand/O the/O withdrawal/O of/O British/B-gpe troops/O from/O that/O country/O ./O'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "xy = [\"{}/{}\".format(x,y) for x,y in zip(X[i],Y[i])]\n",
    "\" \".join(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thousands',\n",
       " 'of',\n",
       " 'demonstrators',\n",
       " 'have',\n",
       " 'marched',\n",
       " 'through',\n",
       " 'London',\n",
       " 'to',\n",
       " 'protest',\n",
       " 'the',\n",
       " 'war',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'and',\n",
       " 'demand',\n",
       " 'the',\n",
       " 'withdrawal',\n",
       " 'of',\n",
       " 'British',\n",
       " 'troops',\n",
       " 'from',\n",
       " 'that',\n",
       " 'country',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_to_pos(X):\n",
    "\n",
    "    word_to_pos = {}\n",
    "    i = 0\n",
    "    for s in X:\n",
    "        for w in s:\n",
    "            if w not in word_to_pos:\n",
    "                word_to_pos[w] = i\n",
    "                i +=1\n",
    "                \n",
    "    pos_to_word = {v: k for k, v in word_to_pos.items()}\n",
    "    return word_to_pos, pos_to_word\n",
    "            \n",
    "def build_tag_to_pos(Y):\n",
    "    tag_to_pos = {}\n",
    "    i = 0\n",
    "    for s in Y:\n",
    "        for t in s:\n",
    "            if t not in tag_to_pos:\n",
    "                tag_to_pos[t] = i\n",
    "                i +=1\n",
    "    pos_to_tag = {v: k for k, v in tag_to_pos.items()}\n",
    "\n",
    "    return tag_to_pos, pos_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7047, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_pos, pos_to_word = build_word_to_pos(X)\n",
    "tag_to_pos, pos_to_tag  = build_tag_to_pos(Y)\n",
    "\n",
    "len(word_to_pos), len(tag_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo': 1,\n",
       " 'B-gpe': 2,\n",
       " 'B-per': 3,\n",
       " 'I-geo': 4,\n",
       " 'B-org': 5,\n",
       " 'I-org': 6,\n",
       " 'B-tim': 7,\n",
       " 'B-art': 8,\n",
       " 'I-art': 9,\n",
       " 'I-per': 10,\n",
       " 'I-gpe': 11,\n",
       " 'I-tim': 12,\n",
       " 'B-nat': 13,\n",
       " 'B-eve': 14,\n",
       " 'I-eve': 15,\n",
       " 'I-nat': 16}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ids = [[word_to_pos[w] for w in s] for s in X]\n",
    "Y_ids = [[tag_to_pos[t] for t in s] for s in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999, 1999)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X),len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Structured perceptron with the provided dada\n",
    "\n",
    "Add new features to the structured perceptron to deal with particular classes found in your data\n",
    "\n",
    "\n",
    "The class ExtendedFeatures can be expanded.\n",
    "\n",
    "For example you can add inside the method add_emission_features the following:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "        if word.istitle():\n",
    "            # Generate feature name.\n",
    "            feat_name = \"uppercased::%s\" % y_name\n",
    "            # Get feature ID from name.\n",
    "            feat_id = self.add_feature(feat_name)\n",
    "            # Append feature.\n",
    "            if feat_id != -1:\n",
    "                features.append(feat_id)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "import skseq\n",
    "\n",
    "from skseq.sequences import sequence\n",
    "from skseq.sequences.sequence import Sequence\n",
    "from skseq.sequences.sequence_list import SequenceList\n",
    "from skseq.sequences.label_dictionary import LabelDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thousands/O of/O demonstrators/O have/O marched/O through/O London/B-geo to/O protest/O the/O war/O in/O Iraq/B-geo and/O demand/O the/O withdrawal/O of/O British/B-gpe troops/O from/O that/O country/O ./O "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = Sequence(x=X[0], y=Y[0])\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_list = SequenceList(LabelDictionary(word_to_pos), LabelDictionary(tag_to_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in zip(X,Y):\n",
    "    sequence_list.add_sequence(x,y, LabelDictionary(word_to_pos), LabelDictionary(tag_to_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0/0 1/0 2/0 3/0 4/0 5/0 6/1 7/0 8/0 9/0 10/0 11/0 12/1 13/0 14/0 9/0 15/0 1/0 16/2 17/0 18/0 19/0 20/0 21/0 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands/O of/O demonstrators/O have/O marched/O through/O London/B-geo to/O protest/O the/O war/O in/O Iraq/B-geo and/O demand/O the/O withdrawal/O of/O British/B-gpe troops/O from/O that/O country/O ./O '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_list[0].to_words(sequence_list=sequence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building features form the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(sequence_list)\n",
    "feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_dict',\n",
      " 'feature_list',\n",
      " 'add_features',\n",
      " 'dataset',\n",
      " 'node_feature_cache',\n",
      " 'initial_state_feature_cache',\n",
      " 'final_state_feature_cache',\n",
      " 'edge_feature_cache']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(list(feature_mapper.__dict__.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7891"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_mapper.feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_mapper.feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['init_tag:O',\n",
       " 'id:Thousands::O',\n",
       " 'id:of::O',\n",
       " 'prev_tag:O::O',\n",
       " 'id:demonstrators::O']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_mapper.feature_dict)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['init_tag:O',\n",
       " 'id:Thousands::O',\n",
       " 'id:of::O',\n",
       " 'prev_tag:O::O',\n",
       " 'id:demonstrators::O',\n",
       " 'id:have::O',\n",
       " 'id:marched::O',\n",
       " 'id:through::O',\n",
       " 'id:London::B-geo',\n",
       " 'prev_tag:O::B-geo']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_mapper.feature_dict)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_prev_tag', 'id', 'init_tag', 'prev_tag'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x.split(\":\")[0] for x in feature_mapper.feature_dict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0]],\n",
       " [[3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [44],\n",
       "  [46],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3],\n",
       "  [3]],\n",
       " [[28]],\n",
       " [[29],\n",
       "  [2],\n",
       "  [30],\n",
       "  [31],\n",
       "  [15],\n",
       "  [13],\n",
       "  [32],\n",
       "  [33],\n",
       "  [13],\n",
       "  [34],\n",
       "  [35],\n",
       "  [36],\n",
       "  [37],\n",
       "  [38],\n",
       "  [39],\n",
       "  [40],\n",
       "  [41],\n",
       "  [42],\n",
       "  [43],\n",
       "  [45],\n",
       "  [47],\n",
       "  [48],\n",
       "  [42],\n",
       "  [17],\n",
       "  [42],\n",
       "  [49],\n",
       "  [13],\n",
       "  [50],\n",
       "  [27],\n",
       "  [42]]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of features activated for the first example\n",
    "feature_mapper.feature_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training structured perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skseq.readers.pos_corpus\n",
    "corpus = skseq.readers.pos_corpus.PostagCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skseq.sequences.structured_perceptron as spc\n",
    "\n",
    "sp = spc.StructuredPerceptron(word_to_pos, tag_to_pos, feature_mapper)\n",
    "sp.num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 7047)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.get_num_states(), sp.get_num_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.797048\n",
      "Epoch: 1 Accuracy: 0.855730\n",
      "Epoch: 2 Accuracy: 0.886423\n",
      "Epoch: 3 Accuracy: 0.906794\n",
      "Epoch: 4 Accuracy: 0.918017\n",
      "Epoch: 5 Accuracy: 0.928113\n",
      "Epoch: 6 Accuracy: 0.939628\n",
      "Epoch: 7 Accuracy: 0.935144\n",
      "Epoch: 8 Accuracy: 0.951617\n",
      "Epoch: 9 Accuracy: 0.950310\n",
      "Epoch: 10 Accuracy: 0.956146\n",
      "Epoch: 11 Accuracy: 0.956868\n",
      "Epoch: 12 Accuracy: 0.962389\n",
      "Epoch: 13 Accuracy: 0.959910\n",
      "Epoch: 14 Accuracy: 0.964011\n",
      "CPU times: user 3min, sys: 789 ms, total: 3min 1s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 15\n",
    "sp.fit(feature_mapper.dataset, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to give a new phrase to the structured perceptron\n",
    "\n",
    "- Remember that the structured perceptron `viterbi_decode` method needs a `Sequence` object\n",
    "\n",
    "\n",
    "- If you want to predict a set of tags for a new phrase you can create a `Sequence` object and fill the object with 0 values.\n",
    "\n",
    "Let's look at a couple of  examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"Sara had been to London for years yet she wanted to go back to Barcelona .\"\n",
    "new_seq = skseq.sequences.sequence.Sequence(x=p.split(), y=[int(0) for w in p.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sara/0 had/0 been/0 to/0 London/1 for/0 years/0 yet/0 she/0 wanted/0 to/0 go/0 back/0 to/0 Barcelona/0 ./0 ,\n",
       " 279.66666666666674)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.viterbi_decode(new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seq = skseq.sequences.sequence.Sequence(x=X[0], y=[int(0) for w in p.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thousands/0 of/0 demonstrators/0 have/0 marched/0 through/0 London/1 to/0 protest/0 the/0 war/0 in/0 Iraq/1 and/0 demand/0 the/0 withdrawal/0 of/0 British/2 troops/0 from/0 that/0 country/0 ./0 "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_hat = sp.viterbi_decode(new_seq)[0]\n",
    "xy_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands/O of/O demonstrators/O have/O marched/O through/O London/B-geo to/O protest/O the/O war/O in/O Iraq/B-geo and/O demand/O the/O withdrawal/O of/O British/B-gpe troops/O from/O that/O country/O ./O '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_hat.to_words(sequence_list=sequence_list, only_tag_translation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Torch introduction\n",
    "\n",
    "Inside `torch.nn` there are several layer objects already build into `torch`. We can use them to build more complex neural networks.\n",
    "\n",
    "- torch.nn.Linear\n",
    "- torch.nn.Embedding\n",
    "- torch.nn.LogSoftmax\n",
    "- torch.nn.Dropout\n",
    "- torch.nn.ReLU\n",
    "- torch.nn.GRU\n",
    "\n",
    "\n",
    "**It is important to notice that, in order to use  the forward method  already implemented in those layers we need to use as input data  formatted as `torch.Variable` type:**\n",
    "```\n",
    "n_input = 3\n",
    "n_output = 2\n",
    "sample = torch.autograd.Variable(torch.Tensor([5.,4.,3.]))\n",
    "linear_layer = torch.nn.Linear(n_input, n_output)\n",
    "linear_layer.forward(sample)\n",
    "```\n",
    "\n",
    "\n",
    "**Thefore if we define an example as a `torch.tensor` we will not be able to forward propagate it:**\n",
    "\n",
    "```\n",
    "n_input = 3\n",
    "n_output = 2\n",
    "sample = torch.Tensor([5.,4.,3.])\n",
    "linear_layer = torch.nn.Linear(n_input, n_output)\n",
    "linear_layer.forward(sample) # -------------------> this does not work\n",
    "```\n",
    "\n",
    "## About recurrent neural networks\n",
    "\n",
    "- RNNCell does the forward pass for a single time step of a sequence (specially usefull if you want to do \"custom\" operatios at every time step).\n",
    "- RNN applies the RNNCell forward pass to every time step of an input sequence (just like the traditional RNN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.Tensor(np.random.rand(3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear layer in numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 3), (3, 1))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.random.seed(1234)\n",
    "W = np.random.rand(2, 3)\n",
    "x = np.random.rand(3, 1)\n",
    "W.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19151945, 0.62210877, 0.43772774],\n",
       "       [0.78535858, 0.77997581, 0.27259261]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27646426],\n",
       "       [0.80187218],\n",
       "       [0.95813935]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97120417],\n",
       "       [1.10374618]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(W, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97120417],\n",
       "       [1.10374618]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W @ x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=2, bias=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_input = 3\n",
    "n_output = 2\n",
    "\n",
    "torch.manual_seed(1000)\n",
    "sample = torch.autograd.Variable(torch.Tensor([5.,4.,3.]))\n",
    "\n",
    "linear_layer = torch.nn.Linear(n_input, n_output)\n",
    "linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2091,  0.1311, -0.0672],\n",
       "        [-0.2794, -0.2628,  0.1456]], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0681, -0.1556], requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7907, -2.1668], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.forward(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.79068434, -2.166812  ], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve the weights and biases from the network to numpy as follows:\n",
    "W_np = linear_layer.weight.data.numpy()\n",
    "b_np = linear_layer.bias.data.numpy()\n",
    "x_np = sample.data.numpy()\n",
    "W_np @ x_np + b_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['weight', 'bias'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(5000, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_input = 5000\n",
    "n_output = 10\n",
    "embedding = torch.nn.Embedding(n_input, n_output)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.LongTensor([506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0018,  1.7398,  0.0347, -0.1383, -0.0893, -0.4650, -0.1623,  0.1137,\n",
       "         -0.3421, -0.2518]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.forward(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3879,  1.2894, -0.9362,  ...,  0.2743, -0.8496,  0.3947],\n",
       "        [ 0.0848,  0.1864,  0.0859,  ...,  1.0726,  1.0481,  1.0527],\n",
       "        [-0.6424, -1.2234, -1.0794,  ..., -0.0482,  0.6610, -0.8908],\n",
       "        ...,\n",
       "        [-0.4186,  0.0305, -0.7265,  ...,  0.0622, -0.1281,  0.8795],\n",
       "        [ 0.2722, -0.7068,  0.7342,  ...,  0.8290, -0.4435, -0.0754],\n",
       "        [-0.4442,  0.8973, -1.2622,  ..., -1.2709, -1.1286,  0.7347]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['weight'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1915, 0.6221, 0.4377, 0.7854, 0.7800, 0.2726]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "gru = torch.nn.GRU(6, 256)\n",
    "sample = torch.autograd.Variable(torch.Tensor(np.random.rand(6).reshape(1,1,6)))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gru.forward(sample)), len(gru.forward(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,_ = gru.forward(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(list(gru.state_dict().keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.GRU bidirectional\n",
    "\n",
    "If we want to generate a representation that takes into account a sequence read from left to righ and from right to left we can use the `bidirectional=true` argument. This will double the number of parameters in our `gru` network. In fact this generates two GRU networks generating in the forward pass the concatenation of the output of both GRUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1915, 0.6221, 0.4377, 0.7854, 0.7800, 0.2726]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "gru = torch.nn.GRU(6, 256, bidirectional=True)\n",
    "sample = torch.Tensor(np.random.rand(6).reshape(1,1,6))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gru.forward(sample)), len(gru.forward(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,_ = gru.forward(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that the forward pass returns a 512 vector instead of 256. \n",
    "# This is because what is returned is the concatenation of two vectors: \n",
    "# one from the \"left_to_right\" GRU  and the other from the \"right_to_left\" GRU.\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weight_ih_l0',\n",
      " 'weight_hh_l0',\n",
      " 'bias_ih_l0',\n",
      " 'bias_hh_l0',\n",
      " 'weight_ih_l0_reverse',\n",
      " 'weight_hh_l0_reverse',\n",
      " 'bias_ih_l0_reverse',\n",
      " 'bias_hh_l0_reverse']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(list(gru.state_dict().keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding shapes in a GRU bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0461,  0.4024, -1.0115,  0.2167, -0.6123])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "random_input = torch.FloatTensor(5, 1, 1).normal_()\n",
    "random_input[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grus = torch.nn.GRU(input_size=1, hidden_size=1, num_layers=1, batch_first=False, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_gru = torch.nn.GRU(input_size=1, hidden_size=1, num_layers=1, batch_first=False, bidirectional=False)\n",
    "reverse_gru.weight_ih_l0 = bi_grus.weight_ih_l0_reverse\n",
    "reverse_gru.weight_hh_l0 = bi_grus.weight_hh_l0_reverse\n",
    "reverse_gru.bias_ih_l0 = bi_grus.bias_ih_l0_reverse\n",
    "reverse_gru.bias_hh_l0 = bi_grus.bias_hh_l0_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_output, bi_hidden = bi_grus(random_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_output, reverse_hidden = reverse_gru(random_input[np.arange(4, -1, -1), :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4095, 0.4667, 0.5444, 0.5134, 0.5124], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_output[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5124, 0.5134, 0.5444, 0.4667, 0.4095], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_output[:, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5124]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4491]],\n",
       "\n",
       "        [[0.5124]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking GRU units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = torch.nn.GRU(input_size = 10, hidden_size=20, num_layers=2)\n",
    "rnn.input_size, rnn.hidden_size, rnn.num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 20]), torch.Size([2, 3, 20]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)\n",
    "output.size(), hn.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch NER demo for deliverable 2\n",
    "\n",
    "This demo is UNFINISHED.\n",
    "\n",
    "It is basically the code found  https://cs230-stanford.github.io/pytorch-nlp.html\n",
    "and it's important you take time to finish it and understand it. It's your job to make it work in a way that you like how it is behaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []        \n",
    "train_labels = []\n",
    "\n",
    "for x in X:\n",
    "    # replace each token by its index if it is in vocab\n",
    "    # else use index of UNK\n",
    "    s = [word_to_pos[token] if token in word_to_pos \n",
    "         else vocab['UNK'] for token in x]\n",
    "    train_sentences.append(s)\n",
    "    \n",
    "for y in Y:\n",
    "    # replace each label by its index\n",
    "    l = [tag_to_pos[label] for label in y]\n",
    "    train_labels.append(l)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.batch_size      = params.batch_size\n",
    "        self.batch_max_len   = params.batch_max_len\n",
    "        self.lstm_hidden_dim = params.lstm_hidden_dim\n",
    "        \n",
    "        # maps each token to an embedding_dim vector\n",
    "        self.embedding = nn.Embedding(params.vocab_size, params.embedding_dim)\n",
    "\n",
    "        # the LSTM takens embedded sentence\n",
    "        self.lstm = nn.LSTM(params.embedding_dim, params.lstm_hidden_dim, batch_first=True)\n",
    "\n",
    "        # fc layer transforms the output to give the final output layer\n",
    "        self.fc = nn.Linear(params.lstm_hidden_dim, params.number_of_tags)\n",
    "\n",
    "    def forward(self, s):\n",
    "        # apply the embedding layer that maps each token to its embedding\n",
    "        s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim\n",
    "\n",
    "        # run the LSTM along the sentences of length batch_max_len\n",
    "        s, _ = self.lstm(s)     # dim: batch_size x batch_max_len x lstm_hidden_dim                \n",
    "\n",
    "        # reshape the Variable so that each row contains one token\n",
    "        s = s.contiguous()\n",
    "        s = s.view(self.batch_size, self.batch_max_len, self.lstm_hidden_dim)  # dim: batch_size*batch_max_len x lstm_hidden_dim\n",
    "\n",
    "        # apply the fully connected layer and obtain the output for each token\n",
    "        s = self.fc(s)          # dim: batch_size*batch_max_len x num_tags\n",
    "\n",
    "        return F.log_softmax(s, dim=1)   # dim: batch_size*batch_max_len x num_tags\n",
    "\n",
    "    def loss_fn(self, outputs, labels):\n",
    "      # reshape labels to give a flat vector of length batch_size*seq_len\n",
    "      labels = labels.view(-1)  \n",
    "\n",
    "      # mask out 'PAD' tokens\n",
    "      mask = (labels >= 0).float()\n",
    "\n",
    "      # the number of tokens is the sum of elements in mask\n",
    "      num_tokens = int(torch.sum(mask).data[0])\n",
    "\n",
    "      # pick the values corresponding to labels and multiply by mask\n",
    "      outputs = outputs[range(outputs.shape[0]), labels]*mask\n",
    "\n",
    "      # cross entropy loss for all non 'PAD' tokens\n",
    "      return -torch.sum(outputs)/num_tokens\n",
    "    \n",
    "    \n",
    "    def optimize(self, batch):\n",
    "        \n",
    "        batch_cost = self.forward(batch)\n",
    "        batch_cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "Params = collections.namedtuple(\"Params\", \n",
    "                                (\"vocab_size\", \n",
    "                                 \"embedding_dim\",\n",
    "                                 \"lstm_hidden_dim\",\n",
    "                                 \"number_of_tags\",\n",
    "                                 \"batch_size\",\n",
    "                                 \"batch_max_len\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params(vocab_size=7047, embedding_dim=200, lstm_hidden_dim=100, number_of_tags=17, batch_size=5, batch_max_len=20)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size       = len(word_to_pos)\n",
    "embedding_dim    = 200\n",
    "lstm_hidden_dim  = 100\n",
    "number_of_tags   = len(tag_to_pos)\n",
    "batch_size       = 5\n",
    "natch_max_len    = 20\n",
    "\n",
    "params = Params(vocab_size, embedding_dim, lstm_hidden_dim, number_of_tags, batch_size,natch_max_len)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(7047, 200)\n",
       "  (lstm): LSTM(200, 100, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(params)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example in a minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10,  23, 506, 123],\n",
       "        [ 10,  23,   0,   0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.autograd.Variable(torch.LongTensor([[10, 23, 506,123], \n",
    "                                              [10, 23, 0,0 ]]))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.batch_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[5, 20, 100]' is invalid for input of size 800",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-bf2e71caa202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# will not work because shapes are not correctly matched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-6aaab822e9f4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# reshape the Variable so that each row contains one token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_hidden_dim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dim: batch_size*batch_max_len x lstm_hidden_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# apply the fully connected layer and obtain the output for each token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[5, 20, 100]' is invalid for input of size 800"
     ]
    }
   ],
   "source": [
    "# will not work because shapes are not correctly matched\n",
    "net.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.batch_size    = 2\n",
    "net.batch_max_len = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 17])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 17])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_to_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! We have now a model, but how do we pass data to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 4 at dim 1 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-e39dc95c2719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this does not work, not all elements in the minatch have the size number of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m x = torch.autograd.Variable(torch.LongTensor([[10, 23, 506,123], \n\u001b[0;32m----> 3\u001b[0;31m                                               [10, 23]]))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 1 (got 2)"
     ]
    }
   ],
   "source": [
    "# this does not work, not all elements in the minatch have the size number of words\n",
    "x = torch.autograd.Variable(torch.LongTensor([[10, 23, 506,123], \n",
    "                                              [10, 23]]))\n",
    "\n",
    "x.shape, net.embedding.forward(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4]), torch.Size([2, 4, 200]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this works though\n",
    "x = torch.autograd.Variable(torch.LongTensor([[10, 23, 506,123], \n",
    "                                              [10, 23, 0,0 ]]))\n",
    "\n",
    "x.shape, net.embedding.forward(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(7047, 200)\n",
       "  (lstm): LSTM(200, 100, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0820, -0.3499, -0.2617,  ..., -1.8986, -0.6394, -1.3620],\n",
       "         [-0.1558, -0.8640, -0.0093,  ...,  0.4334,  1.7331,  0.8474],\n",
       "         [-1.5315,  0.5984,  0.3271,  ...,  0.0236, -0.6438,  1.7018],\n",
       "         [ 1.6441,  1.1248,  0.5879,  ..., -0.3087,  0.9252, -0.1380]],\n",
       "\n",
       "        [[-1.0820, -0.3499, -0.2617,  ..., -1.8986, -0.6394, -1.3620],\n",
       "         [-0.1558, -0.8640, -0.0093,  ...,  0.4334,  1.7331,  0.8474],\n",
       "         [-0.8533, -0.1075,  1.0569,  ..., -1.3179,  0.2390, -0.4962],\n",
       "         [-0.8533, -0.1075,  1.0569,  ..., -1.3179,  0.2390, -0.4962]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.embedding.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded = net.embedding.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out, _ = net.lstm.forward(x_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 100])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dim: batch_size x batch_max_len x lstm_hidden_dim\n",
    "lstm_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 100])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out.view(size =  (2,4, 100)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 100])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = lstm_out.contiguous()\n",
    "aux.view(size =  (4,2,100)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the loss given the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn( outputs, labels):\n",
    "    # reshape labels to give a flat vector of length batch_size*seq_len\n",
    "    labels = labels.view(-1)  \n",
    "\n",
    "    # mask out 'PAD' tokens\n",
    "    mask = (labels >= 0).float()\n",
    "\n",
    "    # the number of tokens is the sum of elements in mask\n",
    "    num_tokens = int(torch.sum(mask).data[0])\n",
    "\n",
    "    # pick the values corresponding to labels and multiply by mask\n",
    "    outputs = outputs[range(outputs.shape[0]), labels]*mask\n",
    "\n",
    "    # cross entropy loss for all non 'PAD' tokens\n",
    "    return -torch.sum(outputs)/num_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-3bfc94341ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "y.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 0, 0],\n",
       "        [1, 5, 0, 0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.autograd.Variable(torch.LongTensor([[3, 6, 0, 0], \n",
    "                                              [1, 5, 0, 0]]))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-bd7f0816b15a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# what is going on? Notice the dimension missmatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-105-a1326724c5a9>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(outputs, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# the number of tokens is the sum of elements in mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# pick the values corresponding to labels and multiply by mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "# what is going on? Notice the dimension missmatch\n",
    "loss_fn(out,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making an output batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = torch.autograd.Variable(torch.LongTensor([[3, 6, 0, 0], \n",
    "#                                              [1, 5, 0, 0]]))\n",
    "\n",
    "y = torch.LongTensor([[3, 6, 0, 0], [1, 5, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 17])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 0, 0],\n",
       "        [1, 5, 0, 0]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot = torch.zeros(y.size()[0], y.size()[1], len(tag_to_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 3, 0],\n",
       "        [1, 5, 0, 0]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.autograd.Variable(torch.LongTensor([[3, 6, 3, 0], \n",
    "                                              [1, 5, 0, 0]]))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example in the batch 0, word position 0, tag value 3\n",
      "example in the batch 0, word position 1, tag value 6\n",
      "example in the batch 0, word position 2, tag value 3\n",
      "example in the batch 0, word position 3, tag value 0\n",
      "example in the batch 1, word position 0, tag value 1\n",
      "example in the batch 1, word position 1, tag value 5\n",
      "example in the batch 1, word position 2, tag value 0\n",
      "example in the batch 1, word position 3, tag value 0\n"
     ]
    }
   ],
   "source": [
    "y_onehot = torch.zeros(y.size()[0], y.size()[1], len(tag_to_pos))\n",
    "\n",
    "for m,y_onehot_m in enumerate(y_onehot):\n",
    "    for k,y_k in enumerate(y[m]):\n",
    "        print(\"example in the batch {}, word position {}, tag value {}\".format(m,k, int(y_k)))\n",
    "        if int(y_k) == 0:\n",
    "            y_onehot[m][k][0] = -1.\n",
    "        else:\n",
    "            y_onehot[m][k][int(y_k)] = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.],\n",
       "        [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 3, 0],\n",
       "        [1, 5, 0, 0]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare this function with the one in the URL from standford\n",
    "# Do you think this one makes sense?\n",
    "def loss_fn( outputs, labels):\n",
    "    \n",
    "    # reshape labels to give a flat vector of length batch_size*seq_len\n",
    "    labels = labels.view(-1)  \n",
    "\n",
    "    # mask out 'PAD' tokens\n",
    "    mask = (labels == -1).float()\n",
    "\n",
    "    # the number of tokens is the sum of elements in mask\n",
    "    num_tokens = int(torch.sum(mask))\n",
    "\n",
    "    # pick the values corresponding to labels and multiply by mask\n",
    "    outputs_vec = outputs.view(-1)\n",
    "    outputs     = outputs_vec*mask\n",
    "\n",
    "    # cross entropy loss for all non 'PAD' tokens\n",
    "    return -torch.sum(outputs)/num_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 17]), torch.Size([2, 4, 17]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(), y_onehot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = loss_fn(out,y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4095, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#x_ = torch.tensor(x)\n",
    "output = loss_fn(net.forward(x), y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(7047, 200)\n",
       "  (lstm): LSTM(200, 100, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0409, -0.0827, -0.0102,  ...,  0.0015,  0.0788,  0.0280],\n",
       "        [-0.0629, -0.0377,  0.0444,  ...,  0.0102,  0.0899,  0.0045],\n",
       "        [-0.0388,  0.0898, -0.0379,  ..., -0.0534, -0.0037,  0.0769],\n",
       "        ...,\n",
       "        [-0.0695, -0.0391, -0.0578,  ..., -0.0680, -0.0798,  0.0553],\n",
       "        [ 0.0690,  0.0172, -0.0031,  ...,  0.0866,  0.0573, -0.0887],\n",
       "        [ 0.0994, -0.0768, -0.0748,  ..., -0.0103,  0.0365, -0.0394]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "# Apply gradients\n",
    "for param in net.parameters():\n",
    "    param.data.add_(-learning_rate * param.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0450, -0.0724, -0.0159,  ..., -0.0054,  0.0766,  0.0273],\n",
       "        [-0.0629, -0.0377,  0.0444,  ...,  0.0102,  0.0899,  0.0045],\n",
       "        [-0.0388,  0.0898, -0.0379,  ..., -0.0534, -0.0037,  0.0769],\n",
       "        ...,\n",
       "        [-0.0695, -0.0391, -0.0578,  ..., -0.0680, -0.0798,  0.0553],\n",
       "        [ 0.0690,  0.0172, -0.0031,  ...,  0.0866,  0.0573, -0.0887],\n",
       "        [ 0.0994, -0.0768, -0.0748,  ..., -0.0103,  0.0365, -0.0394]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using optimizers\n",
    "\n",
    "\n",
    "You can also use optimizers build into pytorch\n",
    "```\n",
    "optimizer             = optim.SGD(network.parameters(), lr=learning_rate)\n",
    "optimizer             = optim.Adam(network.parameters(), lr = learning_rate)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
